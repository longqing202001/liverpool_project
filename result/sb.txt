

Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
/content/drive/My Drive/liverpool/sb/sb.py:45: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=[<tf.Tenso...)`
  model = Model(input=inputs, output=[predictions])
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (256, 1, 52284)           0         
_________________________________________________________________
gru_1 (GRU)                  [(256, 100), (256, 100)]  15715500  
_________________________________________________________________
dropout_1 (Dropout)          (256, 100)                0         
_________________________________________________________________
dense_1 (Dense)              (256, 52284)              5280684   
=================================================================
Total params: 20,996,184
Trainable params: 20,996,184
Non-trainable params: 0
_________________________________________________________________
None
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.

  0% 0/548864 [00:00<?, ?it/s]Training epoch 0. 
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-01-10 07:58:52.874113: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-01-10 07:58:52.885948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000170000 Hz
2020-01-10 07:58:52.890075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e62f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-01-10 07:58:52.890113: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-01-10 07:58:52.895266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-01-10 07:58:53.073728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-10 07:58:53.074483: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e63b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-01-10 07:58:53.074514: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-01-10 07:58:53.075806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-10 07:58:53.076427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
2020-01-10 07:58:53.091813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-10 07:58:53.312104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-10 07:58:53.446133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-10 07:58:53.469459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-10 07:58:53.728176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-10 07:58:53.766954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-10 07:58:54.262649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-10 07:58:54.262834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-10 07:58:54.263580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-10 07:58:54.264162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-01-10 07:58:54.269645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-10 07:58:54.270899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-10 07:58:54.270935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-01-10 07:58:54.270951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-01-10 07:58:54.273682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-10 07:58:54.274406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-10 07:58:54.275028: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-01-10 07:58:54.275072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

2020-01-10 07:59:02.235728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
Epoch 0. Loss: 8.05045: 100% 548864/548864 [03:22<00:00, 2703.80it/s]
tcmalloc: large alloc 1392009216 bytes == 0xbb752000 @  0x7ff21c9241e7 0x7ff21a443f71 0x7ff21a4a755d 0x7ff21a4a7733 0x7ff21a4f378c 0x7ff21a4f7520 0x7ff21a5359e9 0x50ac25 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50b403 0x635222 0x6352d7 0x638a8f 0x639631 0x4b0f40 0x7ff21c521b97 0x5b2fda
Training epoch 0, Training loss = 8.0505,Validation HR@50 = 0.1766, NDCG@50 = 0.0775. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 1. 
Epoch 1. Loss: 6.34849: 100% 548864/548864 [03:06<00:00, 2952.23it/s]
tcmalloc: large alloc 1392009216 bytes == 0xbb752000 @  0x7ff21c9241e7 0x7ff21a443f71 0x7ff21a4a755d 0x7ff21a4a7733 0x7ff21a4f378c 0x7ff21a4f7520 0x7ff21a5359e9 0x50ac25 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50b403 0x635222 0x6352d7 0x638a8f 0x639631 0x4b0f40 0x7ff21c521b97 0x5b2fda
Training epoch 1, Training loss = 6.3485,Validation HR@50 = 0.2670, NDCG@50 = 0.1179. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 2. 
Epoch 2. Loss: 5.46072: 100% 548864/548864 [03:06<00:00, 2933.10it/s]
tcmalloc: large alloc 1392009216 bytes == 0xbb752000 @  0x7ff21c9241e7 0x7ff21a443f71 0x7ff21a4a755d 0x7ff21a4a7733 0x7ff21a4f378c 0x7ff21a4f7520 0x7ff21a5359e9 0x50ac25 0x50c5b9 0x509d48 0x50aa7d 0x50c5b9 0x508245 0x50b403 0x635222 0x6352d7 0x638a8f 0x639631 0x4b0f40 0x7ff21c521b97 0x5b2fda
Training epoch 2, Training loss = 5.4607,Validation HR@50 = 0.3043, NDCG@50 = 0.1384. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 3. 
Epoch 3. Loss: 4.96327: 100% 548864/548864 [03:06<00:00, 2949.75it/s]
Training epoch 3, Training loss = 4.9633,Validation HR@50 = 0.3202, NDCG@50 = 0.1478. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 4. 
Epoch 4. Loss: 4.63835: 100% 548864/548864 [03:06<00:00, 2938.15it/s]
Training epoch 4, Training loss = 4.6384,Validation HR@50 = 0.3304, NDCG@50 = 0.1520. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 5. 
Epoch 5. Loss: 4.21435: 100% 548864/548864 [03:05<00:00, 3031.09it/s]
Training epoch 5, Training loss = 4.2143,Validation HR@50 = 0.3346, NDCG@50 = 0.1544. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 6. 
Epoch 6. Loss: 4.02762: 100% 548864/548864 [02:53<00:00, 3163.31it/s]
Training epoch 6, Training loss = 4.0276,Validation HR@50 = 0.3391, NDCG@50 = 0.1561. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 7. 
Epoch 7. Loss: 3.72313: 100% 548864/548864 [02:53<00:00, 3158.20it/s]
Training epoch 7, Training loss = 3.7231,Validation HR@50 = 0.3418, NDCG@50 = 0.1553. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 8. 
Epoch 8. Loss: 3.50900: 100% 548864/548864 [02:53<00:00, 3155.93it/s]
Training epoch 8, Training loss = 3.5090,Validation HR@50 = 0.3367, NDCG@50 = 0.1551. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 9. 
Epoch 9. Loss: 3.46914: 100% 548864/548864 [02:53<00:00, 3178.41it/s]
Training epoch 9, Training loss = 3.4691,Validation HR@50 = 0.3376, NDCG@50 = 0.1561. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 10. 
Epoch 10. Loss: 3.46157: 100% 548864/548864 [02:53<00:00, 3153.34it/s]
Training epoch 10, Training loss = 3.4616,Validation HR@50 = 0.3382, NDCG@50 = 0.1555. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 11. 
Epoch 11. Loss: 3.19368: 100% 548864/548864 [02:53<00:00, 3180.38it/s]
Training epoch 11, Training loss = 3.1937,Validation HR@50 = 0.3385, NDCG@50 = 0.1548. 
  0% 0/548864 [00:00<?, ?it/s]Training epoch 12. 
Epoch 12. Loss: 3.08265: 100% 548864/548864 [02:53<00:00, 3198.97it/s]
Training epoch 12, Training loss = 3.0826,Validation HR@50 = 0.3361, NDCG@50 = 0.1539. 
End. Best Iteration 7:  HR@50  = 0.3418, NDCG@50 = 0.1553. 


